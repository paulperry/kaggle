{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Western Australia Rental Prices - ETL-12\n",
    "\n",
    "https://www.kaggle.com/c/deloitte-western-australia-rental-prices/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging hadn't been started.\n",
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : ETL12\n",
      "Mode           : rotate\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : False\n",
      "State          : active\n",
      "2015-11-20 22:27:53.047139\n"
     ]
    }
   ],
   "source": [
    "# settings and constants\n",
    "%logstop\n",
    "%logstart  -o 'ETL12' rotate\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "start_time = pd.datetime.now()\n",
    "print start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834570, 5)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train_fix.csv', low_memory=False)\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ren_date_eff_from</th>\n",
       "      <th>ren_base_rent</th>\n",
       "      <th>ve_number</th>\n",
       "      <th>ren_lease_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ren_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1579258</th>\n",
       "      <td>1990-02-13</td>\n",
       "      <td>280</td>\n",
       "      <td>4807702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203979</th>\n",
       "      <td>1990-04-13</td>\n",
       "      <td>115</td>\n",
       "      <td>332135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ren_date_eff_from  ren_base_rent  ve_number ren_lease_length\n",
       "ren_id                                                              \n",
       "1579258        1990-02-13            280    4807702              NaN\n",
       "1203979        1990-04-13            115     332135              NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = map(str.lower, train.columns)\n",
    "train.set_index('ren_id', inplace=True)\n",
    "train.ren_date_eff_from = pd.to_datetime(train.ren_date_eff_from)\n",
    "train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150508, 4)\n"
     ]
    }
   ],
   "source": [
    "#train = pd.read_csv('data/train.csv', low_memory=False)\n",
    "test = pd.read_csv('data/test_fix.csv', low_memory=False)\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ren_date_eff_from</th>\n",
       "      <th>ve_number</th>\n",
       "      <th>ren_lease_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ren_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>2004-02-18</td>\n",
       "      <td>2402939</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>2004-02-18</td>\n",
       "      <td>1352438</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ren_date_eff_from  ve_number ren_lease_length\n",
       "ren_id                                              \n",
       "10568         2004-02-18    2402939              NaN\n",
       "12686         2004-02-18    1352438              NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns = map(str.lower, test.columns)\n",
    "test.set_index('ren_id', inplace=True)\n",
    "test.ren_date_eff_from = pd.to_datetime(test.ren_date_eff_from)\n",
    "test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# based on Mac with Postgres.app\n",
    "# export PATH=\"/Applications/Postgres.app/Contents/Versions/9.4/bin:$PATH\"\n",
    "# then pip install psycopg2\n",
    "# then sudo brew install openssl\n",
    "# and follow these instructions:\n",
    "# http://stackoverflow.com/questions/11365619/psycopg2-installation-error-library-not-loaded-libssl-dylib\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://paulperry:ciao,ciao@localhost:5432/australia', \n",
    "                       connect_args={'client_encoding': 'latin1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantity Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 3.5 s, total: 24.4 s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "# get all the quantities \n",
    "\n",
    "# I'm cleaning up the dupes in python\n",
    "qp1 = \"select t1.ren_id, t1.ve_number, t2.urv_id, t1.ren_date_eff_from, t2.uvv_quantity from \" # query part 1\n",
    "qp2 = \" t1 left join valuation_entities_details t2 \\\n",
    "    on (t1.ve_number = t2.ve_number and t1.ren_date_eff_from > t2.uvv_date_eff_from ) \\\n",
    "    left join valuation_entities_details t3 \\\n",
    "    on (t2.ve_number = t3.ve_number and t2.urv_id = t3.urv_id and t2.urv_date_eff_from < t3.urv_date_eff_from) \\\n",
    "    left join valuation_entities_details t4 \\\n",
    "    on (t3.ve_number = t4.ve_number and t3.urv_id = t4.urv_id and t3.uvv_quantity < t4.uvv_quantity) \\\n",
    "    where t2.urv_ven_quality_ind like 'N' and t2.urv_ven_quantity_ind like 'Y' and t2.uvv_quantity > 0 \\\n",
    "    and t4.urv_date_eff_from is null and t4.uvv_quantity is null \"\n",
    "qp3 = \" order by ren_id, ve_number, urv_id, ren_date_eff_from, uvv_quantity desc;\"\n",
    "\n",
    "fullq = qp1+'train'+qp2+' union all '+qp1+'test'+qp2+qp3\n",
    "\n",
    "%time ve_quantity = pd.read_sql_query(fullq, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7918201, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ren_id</th>\n",
       "      <th>ve_number</th>\n",
       "      <th>urv_id</th>\n",
       "      <th>ren_date_eff_from</th>\n",
       "      <th>uvv_quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>4485377</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4485377</td>\n",
       "      <td>19</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4485377</td>\n",
       "      <td>57</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4485377</td>\n",
       "      <td>58</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4485377</td>\n",
       "      <td>201</td>\n",
       "      <td>2011-07-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ren_id  ve_number  urv_id ren_date_eff_from  uvv_quantity\n",
       "0       6    4485377       4        2011-07-07             1\n",
       "1       6    4485377      19        2011-07-07           217\n",
       "2       6    4485377      57        2011-07-07             1\n",
       "3       6    4485377      58        2011-07-07             4\n",
       "4       6    4485377     201        2011-07-07             1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ve_quantity.shape\n",
    "ve_quantity[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7918201, 5)\n",
      "(7692331, 5)\n"
     ]
    }
   ],
   "source": [
    "# the sql query has duplicates (you go wrestle with that query!), so we delete them here.\n",
    "print ve_quantity.shape\n",
    "ve_quantity.drop_duplicates(['ren_id','ve_number','urv_id'], keep='first', inplace=True) \n",
    "print ve_quantity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulperry/anaconda/lib/python2.7/site-packages/pandas/core/index.py:4281: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return np.sum(name == np.asarray(self.names)) > 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>urv_id</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>405</th>\n",
       "      <th>413</th>\n",
       "      <th>431</th>\n",
       "      <th>434</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>477</th>\n",
       "      <th>479</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ren_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "urv_id  4    5    19   20   21   22   23   24   25   26  ...   405  413  431  \\\n",
       "ren_id                                                   ...                   \n",
       "6         1  NaN  217  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "9       NaN  NaN  119  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "13      NaN  NaN   73  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "26        1  NaN  120  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "27      NaN  NaN   78  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "\n",
       "urv_id  434  440  441  443  444  477  479  \n",
       "ren_id                                     \n",
       "6         1  NaN  NaN    1  NaN  NaN  NaN  \n",
       "9       NaN  NaN  NaN    1  NaN  NaN  NaN  \n",
       "13      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "26      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "27      NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_features = pd.pivot(ve_quantity.ren_id, ve_quantity.urv_id, ve_quantity.uvv_quantity)\n",
    "quantity_features.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stop if somehow we messed up the pivot\n",
    "if len(quantity_features.index) > (len(train.index)+len(test.index)):\n",
    "    raise Exception('bad pivot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urv_description</th>\n",
       "      <th>urv_ven_quality_ind</th>\n",
       "      <th>urv_ven_quantity_ind</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urv_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>EFFECTIVE ROOMS</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1034318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>BEDROOMS</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>924250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>YEAR BUILT</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>923596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>KITCHEN</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>858940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>BRICK  WALLS</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>789499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        urv_description urv_ven_quality_ind urv_ven_quantity_ind        c\n",
       "urv_id                                                                   \n",
       "206     EFFECTIVE ROOMS                   N                    Y  1034318\n",
       "58             BEDROOMS                   N                    Y   924250\n",
       "410          YEAR BUILT                   Y                    N   923596\n",
       "271             KITCHEN                   N                    Y   858940\n",
       "89         BRICK  WALLS                   N                    N   789499"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the valuation entity keys\n",
    "ve_key = pd.read_csv('ve_key.csv')\n",
    "ve_key.set_index('urv_id', inplace=True)\n",
    "ve_key[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # or generate the keys if we don't have the file\n",
    "# q_key =\"select urv_id, urv_description, urv_ven_quality_ind, urv_ven_quantity_ind, count(*) as c \\\n",
    "#     from valuation_entities_details \\\n",
    "#     group by urv_id, urv_description, urv_ven_quality_ind, urv_ven_quantity_ind \\\n",
    "#     order by c desc;\"\n",
    "\n",
    "# ve_key = pd.read_sql_query(q_key, engine)\n",
    "# ve_key.to_csv('ve_key.csv', index=False)\n",
    "# print len(ve_key.index)\n",
    "# ve_key.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    # map columns to ve_key names\n",
    "    col_names = [ve_key.loc[i].urv_description.lower().replace(' ','_').replace('-','_') \n",
    "                 for i in df.columns]\n",
    "    col_names = [s.encode('ascii','ignore') for s in col_names]\n",
    "    col_names = [c.translate(None,\".()&?!;$/\\\\,\") for c in col_names]\n",
    "    if len(col_names) == len(df.columns):\n",
    "        df.columns = col_names\n",
    "    else:\n",
    "        raise Exception('Problem renaming columns!') \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # map the pivot columns to ve_key names\n",
    "# col_names = [ve_key.loc[i].urv_description.lower().replace(' ','_').replace('-','_') \n",
    "#              for i in quantity_features.columns]\n",
    "# col_names = [s.encode('ascii','ignore') for s in col_names]\n",
    "# col_names = [c.translate(None,\".()&?!;$/\\\\,\") for c in col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'activity_room', u'airconditioned', u'house_area', u'office_area_1',\n",
      "       u'shop_area', u'showroom_area', u'store_room_area_1',\n",
      "       u'warehouse_area_1', u'factory_area_1', u'any_other_area',\n",
      "       u'basement_area', u'shed_area_1', u'total_area', u'mezzanine_area',\n",
      "       u'workshop_area_1', u'bar', u'bath_room', u'bedrooms',\n",
      "       u'single_bedrooms', u'carbay_under_cover', u'tandem_carbay',\n",
      "       u'open_car_bay', u'carport_under_main_roof', u'carport_attached',\n",
      "       u'carport_detached', u'dining_room', u'dressing_room',\n",
      "       u'effective_rooms', u'ensuite', u'excess_land', u'family_room',\n",
      "       u'frontage_of_block', u'fronts_onto_lake', u'games__room',\n",
      "       u'detached_gamesroom', u'garage_under_main_roof', u'garage_attached',\n",
      "       u'garage_detached', u'guest_room', u'kennels', u'kitchen', u'laundry',\n",
      "       u'lounge_room', u'meals_area', u'music_room', u'other_rooms',\n",
      "       u'plate_height', u'parents__retreat', u'sleep_out', u'sewing_room',\n",
      "       u'shed', u'sitting_room', u'spa_room', u'stable', u'store_room',\n",
      "       u'storey', u'studio', u'study', u'sun_room', u'television_room',\n",
      "       u'tennis_court', u'number_of_units', u'toilet', u'walk_in_robe',\n",
      "       u'workshop', u'effective_bed_count', u'ven_land_area', u'theatre_room',\n",
      "       u'hall_area', u'jetty', u'alfresco_room', u'kitchenette',\n",
      "       u'area_of_sheds', u'scullery'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "quantity_features = rename_columns(quantity_features)\n",
    "print quantity_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980588, 74)\n"
     ]
    }
   ],
   "source": [
    "print quantity_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "# select only the columns that have enough values to be useful\n",
    "quantity_counts = quantity_features.count().sort_values(ascending=False)\n",
    "good_quantity = quantity_counts[quantity_counts > 50]\n",
    "print len(quantity_features.columns)\n",
    "print len(good_quantity.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms                   945838\n",
       "effective_rooms            864488\n",
       "kitchen                    832704\n",
       "lounge_room                766598\n",
       "house_area                 706986\n",
       "dining_room                528530\n",
       "bath_room                  347549\n",
       "toilet                     313250\n",
       "family_room                298344\n",
       "ensuite                    280293\n",
       "carport_under_main_roof    226453\n",
       "storey                     215556\n",
       "walk_in_robe               201285\n",
       "garage_under_main_roof     169524\n",
       "meals_area                 161487\n",
       "carport_detached           113227\n",
       "store_room                 103240\n",
       "games__room                 93888\n",
       "carport_attached            87182\n",
       "garage_detached             74832\n",
       "study                       66130\n",
       "alfresco_room               44689\n",
       "garage_attached             33619\n",
       "effective_bed_count         32176\n",
       "theatre_room                30767\n",
       "                            ...  \n",
       "airconditioned               1864\n",
       "tennis_court                 1762\n",
       "spa_room                     1701\n",
       "studio                       1559\n",
       "shed_area_1                  1427\n",
       "excess_land                   998\n",
       "sun_room                      855\n",
       "bar                           838\n",
       "total_area                    704\n",
       "stable                        475\n",
       "sewing_room                   344\n",
       "dressing_room                 279\n",
       "office_area_1                 272\n",
       "music_room                    272\n",
       "shop_area                     216\n",
       "television_room               212\n",
       "laundry                       179\n",
       "detached_gamesroom            157\n",
       "guest_room                    154\n",
       "store_room_area_1             150\n",
       "jetty                          99\n",
       "tandem_carbay                  91\n",
       "workshop_area_1                89\n",
       "area_of_sheds                  86\n",
       "kitchenette                    82\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_quantity.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980588, 62)\n"
     ]
    }
   ],
   "source": [
    "# throw out the low count features\n",
    "quantity_features = quantity_features[good_quantity.index]\n",
    "print quantity_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0      326924\n",
       "2.0      300573\n",
       "4.0      164452\n",
       "1.0      141726\n",
       "5.0        8623\n",
       "6.0        3283\n",
       "7.0         194\n",
       "8.0          20\n",
       "9.0          14\n",
       "10.0          7\n",
       "3.5           4\n",
       "14.0          3\n",
       "6.5           3\n",
       "9.5           3\n",
       "5.5           3\n",
       "121.0         2\n",
       "10.5          2\n",
       "7.5           1\n",
       "12.0          1\n",
       "Name: bedrooms, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_features.bedrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# arbirtrarily cut off the high end to avoid that 121 value\n",
    "quantity_features.loc[quantity_features.bedrooms > 10,'bedrooms'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5     98616\n",
       "5.5     96795\n",
       "4.0     86423\n",
       "6.0     76870\n",
       "5.0     69563\n",
       "6.5     56976\n",
       "7.0     50125\n",
       "3.5     45379\n",
       "3.0     42303\n",
       "8.0     40151\n",
       "9.0     35000\n",
       "7.5     31572\n",
       "8.5     30942\n",
       "9.5     23056\n",
       "2.0     20595\n",
       "2.5     18851\n",
       "10.0    15945\n",
       "Name: effective_rooms, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_features.effective_rooms.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# effective_rooms has too many nan's. let's try to recreate the effective_rooms\n",
    "quantity_features.effective_rooms.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bedrooms', 'effective_rooms', 'kitchen', 'lounge_room',\n",
       "       'house_area', 'dining_room', 'bath_room', 'toilet', 'family_room',\n",
       "       'ensuite', 'carport_under_main_roof', 'storey', 'walk_in_robe',\n",
       "       'garage_under_main_roof', 'meals_area', 'carport_detached',\n",
       "       'store_room', 'games__room', 'carport_attached', 'garage_detached',\n",
       "       'study', 'alfresco_room', 'garage_attached', 'effective_bed_count',\n",
       "       'theatre_room', 'sleep_out', 'frontage_of_block', 'any_other_area',\n",
       "       'other_rooms', 'carbay_under_cover', 'activity_room',\n",
       "       'parents__retreat', 'number_of_units', 'sitting_room', 'shed',\n",
       "       'open_car_bay', 'workshop', 'airconditioned', 'tennis_court',\n",
       "       'spa_room', 'studio', 'shed_area_1', 'excess_land', 'sun_room',\n",
       "       'bar', 'total_area', 'stable', 'sewing_room', 'dressing_room',\n",
       "       'office_area_1', 'music_room', 'shop_area', 'television_room',\n",
       "       'laundry', 'detached_gamesroom', 'guest_room', 'store_room_area_1',\n",
       "       'jetty', 'tandem_carbay', 'workshop_area_1', 'area_of_sheds',\n",
       "       'kitchenette'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_features.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are all the room types\n",
    "all_rooms = ['bedrooms', 'kitchen', 'lounge_room','dining_room', 'bath_room', 'family_room', 'meals_area', \n",
    "             'kitchenette', 'store_room', 'games__room', 'study', 'theatre_room', 'sleep_out', \n",
    "             'other_rooms',  'activity_room', 'sitting_room',  'spa_room', 'studio', 'sun_room',\n",
    "             'bar', 'sewing_room', 'dressing_room',  'music_room', 'television_room',\n",
    "             'laundry', 'detached_gamesroom', 'guest_room']\n",
    "\n",
    "# possible rooms we rejected\n",
    "# 'walk_in_robe', 'ensuite', 'workshop', 'alfresco_room',  'parents__retreat',\n",
    "# 'any_other_area', 'office_area_1', 'shop_area', 'workshop_area_1', 'store_room_area_1', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if the room count per feature is too high, then we assume they must be tracking sqm instead, \n",
    "# so we cut these #'s down to 1 for counting purposes\n",
    "room_counts = quantity_features[all_rooms].copy()\n",
    "room_counts[room_counts > 10] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    950180.000000\n",
       "mean          6.075248\n",
       "std           2.743121\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%           6.000000\n",
       "75%           8.000000\n",
       "max          32.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rooms = room_counts.sum(axis=1)\n",
    "total_rooms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ren_id\n",
       "496504     32\n",
       "54828      32\n",
       "4644269    32\n",
       "2186391    28\n",
       "2284612    27\n",
       "1246097    27\n",
       "2464813    26\n",
       "2777228    26\n",
       "3313116    25\n",
       "2103700    25\n",
       "203170     25\n",
       "2030509    25\n",
       "4953486    25\n",
       "61850      25\n",
       "312003     24\n",
       "1124602    24\n",
       "3338451    24\n",
       "2216279    23\n",
       "1205244    23\n",
       "5027368    23\n",
       "5020180    23\n",
       "5088701    23\n",
       "5222356    23\n",
       "3609728    23\n",
       "1254630    23\n",
       "5187025    23\n",
       "5141530    22\n",
       "3763028    22\n",
       "2213838    22\n",
       "471602     22\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these top 30 look suspect, and maybe should be eliminated\n",
    "total_rooms.sort_values(ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms                     4.0\n",
       "effective_rooms              9.5\n",
       "kitchen                      4.0\n",
       "lounge_room                  4.0\n",
       "house_area                 135.0\n",
       "dining_room                  4.0\n",
       "bath_room                    4.0\n",
       "toilet                       2.0\n",
       "family_room                  4.0\n",
       "ensuite                      4.0\n",
       "carport_under_main_roof      1.0\n",
       "storey                       NaN\n",
       "walk_in_robe                 1.0\n",
       "garage_under_main_roof       NaN\n",
       "meals_area                   4.0\n",
       "carport_detached             NaN\n",
       "store_room                   NaN\n",
       "games__room                  4.0\n",
       "carport_attached             NaN\n",
       "garage_detached              NaN\n",
       "Name: 496504, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example, this has 4.0 repeated in too many places ...\n",
    "quantity_features.loc[496504][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantity_features.loc[quantity_features.effective_rooms.isnull(),'effective_rooms'] = total_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see if we fixed the effective_rooms count\n",
    "quantity_features.effective_rooms.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5186"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure what to do with these ...\n",
    "len(quantity_features[quantity_features.number_of_units > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  (980588, 62)\n",
      "null bedrooms:  34750\n",
      "null bed and effective rooms:  2090\n",
      "null bed and effective rooms in test set:  32\n"
     ]
    }
   ],
   "source": [
    "# we are anchored on the fact that a rental either has bedrooms or effective rooms, and if not, we consider it bogus\n",
    "print 'total: ', quantity_features.shape\n",
    "print 'null bedrooms: ',quantity_features.bedrooms.isnull().sum()\n",
    "print 'null bed and effective rooms: ', len(quantity_features[quantity_features.bedrooms.isnull() & \n",
    "                  quantity_features.effective_rooms.isnull()].index)\n",
    "print 'null bed and effective rooms in test set: ', quantity_features[quantity_features.bedrooms.isnull() & \n",
    "                  quantity_features.effective_rooms.isnull()].index.isin(test.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2058, 62)\n"
     ]
    }
   ],
   "source": [
    "# let's drop the bogus rentals from the train set\n",
    "bad_rooms = quantity_features[quantity_features.bedrooms.isnull() & quantity_features.effective_rooms.isnull()]\n",
    "bad_train_rooms = bad_rooms[bad_rooms.index.isin(train.index)]\n",
    "print bad_train_rooms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# make sure we have as many effective_rooms as bedrooms\n",
    "print len(quantity_features[quantity_features.effective_rooms < quantity_features.bedrooms])\n",
    "quantity_features.loc[quantity_features.effective_rooms < quantity_features.bedrooms,'effective_rooms'] = \\\n",
    "    quantity_features[quantity_features.effective_rooms < quantity_features.bedrooms].bedrooms + 2\n",
    "print len(quantity_features[quantity_features.effective_rooms < quantity_features.bedrooms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     829567\n",
       "2.0       3007\n",
       "4.0         53\n",
       "3.0         40\n",
       "1.5         21\n",
       "11.0         6\n",
       "7.0          5\n",
       "12.0         2\n",
       "6.0          2\n",
       "10.0         1\n",
       "Name: kitchen, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at kitchen values\n",
    "quantity_features.kitchen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix all the rows with more than 4 kitchens ! \n",
    "quantity_features.loc[quantity_features.kitchen > 5,'kitchen'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     763353\n",
       "2.0       3104\n",
       "3.0         69\n",
       "4.0         55\n",
       "11.0         7\n",
       "1.5          5\n",
       "13.0         3\n",
       "21.0         2\n",
       "Name: lounge_room, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_features.lounge_room.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix all the rows with more than 4 lounge rooms ! \n",
    "quantity_features.loc[quantity_features.lounge_room > 5,'lounge_room'] = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower count:  1453\n",
      "null bed count:  948412\n",
      "remaining null bed count:  10717\n"
     ]
    }
   ],
   "source": [
    "# make sure we have as many effective_bed_count as bedrooms\n",
    "print 'lower count: ', len(quantity_features[quantity_features.effective_bed_count < quantity_features.bedrooms])\n",
    "# but we found that these numbers seem reasonable so we don't touch them\n",
    "#quantity_features[quantity_features.effective_bed_count < quantity_features.bedrooms][['bedrooms','effective_bed_count']].sort_values(by='effective_bed_count', ascending=False)\n",
    "print 'null bed count: ', quantity_features.effective_bed_count.isnull().sum()\n",
    "quantity_features.loc[quantity_features.effective_bed_count.isnull(),'effective_bed_count'] = quantity_features.bedrooms\n",
    "print 'remaining null bed count: ', quantity_features.effective_bed_count.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# make sure we have as many effective_rooms as effective_bed_count\n",
    "print len(quantity_features[quantity_features.effective_rooms < quantity_features.effective_bed_count])\n",
    "#quantity_features[quantity_features.effective_rooms < quantity_features.effective_bed_count][['bedrooms','effective_rooms', 'effective_bed_count']].sort_values(by='effective_bed_count', ascending=True)\n",
    "# but we found that these numbers seem reasonable so we don't touch them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high effective_rooms:  135\n"
     ]
    }
   ],
   "source": [
    "# quantity_features[quantity_features.effective_rooms > 35].effective_rooms.sort_values(ascending=False)\n",
    "print 'high effective_rooms: ', (quantity_features.effective_rooms > 32).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arbirtrarily cut off the high end\n",
    "quantity_features.loc[quantity_features.effective_rooms > 32,'effective_rooms'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total area is not useful\n",
    "quantity_features[quantity_features.total_area.notnull()].total_area.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i'm not sure I'll look at this:\n",
    "# quantity_features[quantity_features.effective_rooms != total_rooms].effective_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we can inpute the reset of the missing values \n",
    "quantity_features = quantity_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrooms 16 [ 4.  3.  2.  1.  0.  6.  5.  7.  8.]\n",
      "effective_rooms 98 [ 11.    7.    4.5   6.5   6.    9.5   2.5   9.   10. ]\n",
      "kitchen 6 [ 1.   0.   2.   4.   3.   1.5]\n",
      "lounge_room 6 [ 0.   1.   2.   4.   3.   1.5]\n",
      "house_area 12076 [ 217.   119.    73.   120.    78.   114.     0.    45.   140.9]\n",
      "dining_room 7 [  1.   0.   2.   4.   3.   5.  68.]\n",
      "bath_room 10 [  1.    0.    3.    2.    5.    4.    1.5   6.   11. ]\n",
      "toilet 12 [  2.   0.   1.   3.   5.   4.  21.   6.   7.]\n",
      "family_room 10 [  1.    0.    2.    4.    1.5   3.    5.   11.    7. ]\n",
      "ensuite 12 [  1.    0.    3.    2.    4.    6.    5.    1.5  11. ]\n",
      "carport_under_main_roof 11 [  0.   1.   2.   3.   4.  91.  20.   5.  25.]\n",
      "storey 23 [ 1.25  0.    2.    1.    3.    1.5   4.    5.    1.2 ]\n",
      "walk_in_robe 10 [  4.   1.   0.   2.   3.   5.   6.  11.  23.]\n",
      "garage_under_main_roof 12 [  2.   0.   1.   3.   4.  12.   5.  22.   8.]\n",
      "meals_area 5 [ 0.  1.  2.  4.  3.]\n",
      "carport_detached 16 [  0.   1.   2.   6.   3.   5.  16.   7.   4.]\n",
      "store_room 10 [  0.     1.     2.     3.     5.     1.5    0.5   13.    12.25]\n",
      "games__room 8 [  0.    1.    2.    4.    3.    1.5   7.   11. ]\n",
      "carport_attached 9 [  0.   1.   2.   3.  11.  10.   7.   4.   5.]\n",
      "garage_detached 11 [  0.   1.   2.   3.   4.   5.   6.  30.   9.]\n",
      "study 6 [ 1.   0.   2.   3.   4.   0.5]\n",
      "alfresco_room 7 [  1.   0.   2.   4.  31.   3.  12.]\n",
      "garage_attached 7 [  0.   1.   2.   3.   8.   4.  10.]\n",
      "effective_bed_count 15 [ 4.  3.  2.  1.  6.  0.  5.  7.  8.]\n",
      "theatre_room 4 [ 1.   0.   2.   1.5]\n",
      "sleep_out 8 [ 0.  1.  2.  5.  4.  3.  7.  6.]\n",
      "frontage_of_block 1364 [  0.    18.    20.48  20.12  18.61  34.41  10.06  13.4   16.  ]\n",
      "any_other_area 154 [   0.    41.    64.   220.   130.    61.6   68.    48.    22.8]\n",
      "other_rooms 12 [  0.    1.    2.    5.    2.5  32.    3.    4.    6. ]\n",
      "carbay_under_cover 8 [  0.   1.   2.  72.   3.   4.  11.   5.]\n",
      "activity_room 3 [ 1.  0.  2.]\n",
      "parents__retreat 3 [ 1.  0.  2.]\n",
      "number_of_units 32 [  0.   2.   4.   8.  12.   3.  11.  10.   5.]\n",
      "sitting_room 5 [   0.     1.     2.     1.5  167. ]\n",
      "shed 24 [  0.   1.   2.   3.   5.  18.   4.  40.   7.]\n",
      "open_car_bay 7 [  0.   1.   2.  30.   5.   8.   6.]\n",
      "workshop 7 [   0.      1.      2.     22.58  101.    135.     60.  ]\n",
      "airconditioned 6 [ 0.  1.  2.  3.  6.  5.]\n",
      "tennis_court 2 [ 0.  1.]\n",
      "spa_room 3 [ 0.  1.  2.]\n",
      "studio 3 [ 0.   1.   1.5]\n",
      "shed_area_1 196 [   0.     36.     72.     14.6    54.    198.     46.2    90.     56.12]\n",
      "excess_land 24 [ 0.   2.   1.   4.   3.   6.   0.4  7.   2.5]\n",
      "sun_room 4 [ 0.   1.   2.   0.5]\n",
      "bar 3 [ 0.  1.  2.]\n",
      "total_area 29 [   0.   96.   73.   85.   88.   95.  100.  212.  146.]\n",
      "stable 20 [  0.   2.   4.   3.   8.   1.   5.  10.   9.]\n",
      "sewing_room 2 [ 0.  1.]\n",
      "dressing_room 3 [ 0.  1.  2.]\n",
      "office_area_1 67 [   0.  135.  110.    1.  120.   35.  139.  150.   47.]\n",
      "music_room 2 [ 0.  1.]\n",
      "shop_area 27 [   0.   32.   81.   38.   90.   40.   96.   68.  150.]\n",
      "television_room 2 [ 0.  1.]\n",
      "laundry 3 [ 0.  1.  2.]\n",
      "detached_gamesroom 4 [ 0.   1.   2.   1.5]\n",
      "guest_room 2 [ 0.  1.]\n",
      "store_room_area_1 20 [   0.    4.    3.    1.    2.    5.  290.   45.   22.]\n",
      "jetty 3 [ 0.  1.  5.]\n",
      "tandem_carbay 5 [  0.   1.   2.   8.  19.]\n",
      "workshop_area_1 40 [   0.   60.   17.  169.   50.   99.  108.  214.  104.]\n",
      "area_of_sheds 51 [  0.  72.  38.  30.  54.  25.  32.  74.  90.]\n",
      "kitchenette 2 [ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "df = quantity_features\n",
    "for c in df.columns:\n",
    "    valcnt = len(df[c].unique())\n",
    "    vals = df[c].unique()[:9]\n",
    "    print c, valcnt, vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.24 s, sys: 237 ms, total: 4.48 s\n",
      "Wall time: 1min 18s\n",
      "1523314\n"
     ]
    }
   ],
   "source": [
    "# get all the qualities \n",
    "\n",
    "qq1 = \"select t1.ren_id, t1.ve_number, t2.urv_id, t1.ren_date_eff_from, t2.uvv_quality from \"\n",
    "qq2 = \" t1 left join valuation_entities_details t2 \\\n",
    "    on (t1.ve_number = t2.ve_number and t1.ren_date_eff_from > t2.uvv_date_eff_from ) \\\n",
    "    left join valuation_entities_details t3 \\\n",
    "    on (t2.ve_number = t3.ve_number and t2.urv_id = t3.urv_id and t2.urv_date_eff_from < t3.urv_date_eff_from) \\\n",
    "    where t2.urv_ven_quality_ind like 'Y' and t2.urv_ven_quantity_ind like 'N' and t2.uvv_quality <> '' \\\n",
    "    and t3.urv_date_eff_from is null \"\n",
    "qq3 =  \"order by ren_id, ve_number, urv_id, ren_date_eff_from, uvv_quality desc;\"\n",
    "\n",
    "fullqq = qq1+' train '+qq2+' union all '+qq1+' test '+qq2+qq3\n",
    "\n",
    "%time ve_quality = pd.read_sql_query(fullqq, engine)\n",
    "print len(ve_quality.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(ve_quality.index)\n",
    "ve_quality.drop_duplicates(['ren_id','ve_number','urv_id'], keep='first', inplace=True)\n",
    "print len(ve_quality.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ve_quality[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features = ve_quality.pivot('ren_id', 'urv_id', 'uvv_quality')\n",
    "quality_features.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# col_names = [ve_key[ve_key.urv_id == i].urv_description.lower().replace(' ','_').replace('-','_')\n",
    "#             for i in quality_features.columns]\n",
    "# col_names = [s.encode('ascii','ignore') for s in col_names]\n",
    "# col_names = [c.translate(None,\".()&?!;$/\\\\,\") for c in col_names]\n",
    "# col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features = rename_columns(quality_features)\n",
    "print quality_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.condition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just grab the first letter as the indicator\n",
    "quality_features['condition'] = [str(x)[0].upper() if len(str(x)) > 0 else x for x in quality_features.condition] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make some guesses to condense further\n",
    "quality_features.loc[quality_features.condition == 'V','condition'] = 'G' # Very Good = Good\n",
    "quality_features.loc[quality_features.condition == 'E','condition'] = 'N' # Excellent = New\n",
    "quality_features.loc[quality_features.condition == 'O','condition'] = 'F' # Ok = Fair\n",
    "quality_features.loc[quality_features.condition == '' ,'condition'] = 'G' # Blank = Good\n",
    "quality_features.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab the top qualities\n",
    "top_qualities = quality_features.condition.value_counts()[quality_features.condition.value_counts() > 100]\n",
    "top_qualities.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep the top quality features and null out the rest\n",
    "quality_features['condition'] = [x if x in top_qualities.index else NaN for x in quality_features.condition] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute condition with 'Good'\n",
    "quality_features.loc[:,'condition'] = quality_features.condition.fillna('G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.year_built.value_counts(ascending=True)[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.year_built.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.year_effective.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.year_effective.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the latest date and remove dates that are too low or too high and likely wrong\n",
    "quality_features.loc[quality_features.year_built == '','year_built'] = NaN\n",
    "quality_features.loc[quality_features.year_effective == '','year_effective'] = NaN\n",
    "quality_features['year_built'] = map(float, quality_features.year_built)\n",
    "quality_features['year_effective'] = map(float, quality_features.year_effective)\n",
    "quality_features['year_effective_new'] = quality_features[['year_built', 'year_effective']].max(axis=1)\n",
    "quality_features.loc[quality_features.year_effective_new < float(1880),'year_effective_new'] = NaN\n",
    "quality_features.loc[quality_features.year_effective_new > float(2015),'year_effective_new'].year_effective_new = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute missing years with the median \n",
    "quality_features.loc[:,'year_effective_new'] = quality_features.year_effective_new.fillna(quality_features.year_effective_new.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quality_features.drop('year_built', axis=1, inplace=True)\n",
    "quality_features.drop('year_effective', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's review what we have\n",
    "for c in quality_features.columns:\n",
    "    print c, quality_features[c].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the dummy features\n",
    "\n",
    "qr1 = \"select t1.ren_id, t1.ve_number, t2.urv_id, t1.ren_date_eff_from, t2.uvv_quality, t2.uvv_quantity from \"\n",
    "qr2 = \" t1 left join valuation_entities_details t2 \\\n",
    "    on (t1.ve_number = t2.ve_number and t1.ren_date_eff_from > t2.uvv_date_eff_from ) \\\n",
    "    left join valuation_entities_details t3 \\\n",
    "    on (t2.ve_number = t3.ve_number and t2.urv_id = t3.urv_id and t2.urv_date_eff_from < t3.urv_date_eff_from) \\\n",
    "    left join valuation_entities_details t4 \\\n",
    "    on (t3.ve_number = t4.ve_number and t3.urv_id = t4.urv_id and t3.uvv_quantity < t4.uvv_quantity) \\\n",
    "    where t2.urv_ven_quality_ind like 'N' and t2.urv_ven_quantity_ind like 'N' \\\n",
    "    and t3.urv_date_eff_from is null \"\n",
    "qr3 = \" order by ren_id, ve_number, urv_id, ren_date_eff_from, uvv_quantity desc;\"\n",
    "\n",
    "fullqr = qr1+' train '+qr2+' union all '+qr1+' test '+qr2+qr3\n",
    "\n",
    "%time ve_dummy = pd.read_sql_query(fullqr, engine)\n",
    "print len(ve_dummy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "print len(ve_dummy.index)\n",
    "ve_dummy.drop_duplicates(['ren_id', 've_number','urv_id'], keep='first', inplace=True)\n",
    "print len(ve_dummy.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ve_dummy[ve_dummy.uvv_quantity.notnull()].sort_values(by='uvv_quantity', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_quantity = ve_dummy[ve_dummy.uvv_quantity.notnull()].pivot('ren_id', 'urv_id', 'uvv_quantity')\n",
    "dummy_quantity.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dummy_quantity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # remove pesky missing column names\n",
    "# col_names = []\n",
    "# for c in dummy_quantity.columns:\n",
    "#     vvv = ve_key[ve_key.urv_id == c].urv_description.values[0]\n",
    "#     if pd.isnull(vvv):\n",
    "#         print 'found it! ', c\n",
    "#         col_names.append('A'+str(i))\n",
    "#     else:\n",
    "#         col_names.append(vvv)\n",
    "\n",
    "# # fix strings\n",
    "# col_names = [s.replace(' ','_').replace('-','_').lower() for s in col_names]\n",
    "# col_names = [s.encode('ascii','ignore') for s in col_names]\n",
    "# col_names = [c.translate(None,'.()&?!;$/\\\\,') for c in col_names]\n",
    "# print col_names\n",
    "# # name the columns\n",
    "# if len(col_names) == len(dummy_quantity.columns):\n",
    "#     dummy_quantity.columns = col_names\n",
    "# else:\n",
    "#     raise # 'PROBLEM !!!!'\n",
    "# dummy_quantity.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_quantity = rename_columns(dummy_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_quantity.notnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's select a count of features that is relevant\n",
    "dummy_quantity_counts = dummy_quantity.count().sort_values(ascending=False)\n",
    "good_dummy_quantity = dummy_quantity_counts[dummy_quantity_counts > 50]\n",
    "print len(dummy_quantity.columns)\n",
    "print len(good_dummy_quantity.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_quantity_final = dummy_quantity[good_dummy_quantity.index].copy()\n",
    "dummy_quantity_final.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inpute missing values\n",
    "dummy_quantity_final = dummy_quantity_final.fillna(0)\n",
    "dummy_quantity_final.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# did we really fillna ?\n",
    "if dummy_quantity_final.isnull().sum().sum() != 0:\n",
    "    raise Exception('Failed fillna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We keep a dummy variable\n",
    "ve_dummy.uvv_quality = '1'\n",
    "\n",
    "dummy_quality = ve_dummy[ve_dummy.uvv_quantity.isnull()].pivot('ren_id', 'urv_id', 'uvv_quality')\n",
    "dummy_quality.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dummy_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # remove pesky missing column names\n",
    "# col_names = []\n",
    "# for c in dummy_quality.columns:\n",
    "#     vvv = ve_key[ve_key.urv_id == c].urv_description.values[0]\n",
    "#     if pd.isnull(vvv):\n",
    "#         print 'found it! ', c\n",
    "#         col_names.append('A'+str(i))\n",
    "#     else:\n",
    "#         col_names.append(vvv)\n",
    "\n",
    "# col_names = [s.encode('ascii','ignore') for s in col_names]\n",
    "# col_names = [c.translate(None,'.()&?!;$/\\\\,') for c in col_names]\n",
    "# col_names = [s.replace(' ','_').replace('-','_').lower() for s in col_names]\n",
    "# print col_names\n",
    "# # name the columns\n",
    "# if len(col_names) == len(dummy_quality.columns):\n",
    "#     dummy_quality.columns = col_names\n",
    "# else:\n",
    "#     raise # 'PROBLEM !!!!'\n",
    "# dummy_quality.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_quality = rename_columns(dummy_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see what they look like\n",
    "dummy_quality.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: This bus_stop feature appears twice and may need to be dropped but is not a high count\n",
    "print 'bus_stop: ', dummy_quality['bus_stop'].iloc[:,0].notnull().sum()\n",
    "# remove the duplicate columns\n",
    "dummy_quality.drop(['bus_stop'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's select a count of features that is relevant\n",
    "dummy_quality_counts = dummy_quality.count().sort_values(ascending=False)\n",
    "good_dummy_quality = dummy_quality_counts[dummy_quality_counts > 50]\n",
    "print dummy_quality.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_quality_final = dummy_quality[good_dummy_quality.index].copy()\n",
    "print dummy_quality_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inpute missing values\n",
    "dummy_quality_final = dummy_quality_final.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_quality_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove the columns in quality that are already reflected in quantity\n",
    "dummy_overlap = set(dummy_quality_final.columns) & set(dummy_quantity_final.columns)\n",
    "print dummy_overlap\n",
    "for o in dummy_overlap:\n",
    "    dummy_quality_final.drop(o, axis=1, inplace=True)\n",
    "print set(dummy_quality_final.columns) & set(dummy_quantity_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see if the deleted columns in quality are really in quantity\n",
    "dummy_quantity_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's review what we have\n",
    "for c in dummy_quantity_final.columns:\n",
    "    print c, dummy_quantity_final[c].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the demographic features\n",
    "\n",
    "qd1 = \"select t1.ren_id, t1.ve_number, t3.lan_id, t3.lnp_pin, t3.sa1_7,  \\\n",
    "area_albers_sqm, gccsa_code_2011, sa2_5digitcode_2011, \\\n",
    "sa3_code_2011, sa4_code_2011, state_code_2011,  \\\n",
    "poacode, ra_code11, code, movie_titles, \\\n",
    "groups, groups_1, groups_2, \\\n",
    "predominant_lifestage, financial_status, worklife, area_wealth_dynamic, \\\n",
    "stability_indicator, featurecodegroup, feature_code  \\\n",
    "from \"\n",
    "qd2 = \" t1 \\\n",
    "left join land_valuation_key t2 on (t1.ve_number = t2.ve_number) \\\n",
    "left join demographics_key t3 on (t2.lan_id = t3.lan_id) \\\n",
    "left join demographics t4 on (t3.sa1_7 = t4.sa1_7) \"\n",
    "qd3 = \";\"\n",
    "\n",
    "fullqd = qd1+' train '+qd2+' union all '+qd1+' test '+qd2+qd3\n",
    "\n",
    "%time demo = pd.read_sql_query(fullqd, engine)\n",
    "demo[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(demo.ren_id.unique())\n",
    "print len(demo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the sql query kept some duplicates (!?), so we delete them here.\n",
    "print len(demo.index)\n",
    "demo.drop_duplicates(['ren_id'], keep='last', inplace=True)\n",
    "print len(demo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how many values did we get?\n",
    "demo.notnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in demo.columns:\n",
    "    valcnt = len(demo[c].unique())\n",
    "    if valcnt < 15:\n",
    "        vals = demo[c].unique()\n",
    "    else:\n",
    "        vals = demo[c][:5].values\n",
    "    print c, valcnt, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo['area_albers_sqm'].sort_values().plot(use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log(demo['area_albers_sqm']).sort_values()[100000:].plot(use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sa1_7 code description:\n",
    "# http://www.abs.gov.au/ausstats/abs@.nsf/0/7CAFD05E79EB6F81CA257801000C64CD?opendocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.abs.gov.au/websitedbs/D3310114.nsf/home/remoteness+structure\n",
    "# sa_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and what are the unique values ? \n",
    "# for c in transform_cols:\n",
    "#     print c, demo[c].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_cols = [u'movie_titles', u'groups', u'groups_1', u'groups_2', u'predominant_lifestage', u'financial_status',\n",
    "                  u'worklife', u'area_wealth_dynamic', u'stability_indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode the categorical features\n",
    "from sklearn import preprocessing\n",
    "% time demo_encoded = demo[transform_cols].apply(preprocessing.LabelEncoder().fit_transform) \n",
    "demo_encoded[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # and make the categoricals strings\n",
    "# # TODO: use Pandas Categorical types?\n",
    "%time demo_encoded = demo_encoded.apply(lambda y: ['A'+str(x) if pd.notnull(x) else x for x in y])\n",
    "demo_encoded[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_categorical_features = ['sa2_5digitcode_2011', 'state_code_2011', 'poacode', 'sa1_7', 'feature_code', \n",
    "                              'sa4_code_2011', 'featurecodegroup','sa3_code_2011', 'ra_code11', 'code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # categorical\n",
    "# demo_cat = demo[demo_categorical_features].apply(lambda y: ['A'+str(int(x)) if pd.notnull(x) else x for x in y])\n",
    "demo_cat = demo[demo_categorical_features]\n",
    "demo_cat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_orig_cols = list((set(demo.columns) - set(demo_encoded.columns)) - set(demo_cat.columns))\n",
    "demo_orig_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we should not have lost any rows by this point\n",
    "print demo.shape\n",
    "print demo_encoded.shape\n",
    "print demo_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_all = pd.concat([demo[demo_orig_cols], demo_cat, demo_encoded], axis=1)\n",
    "print demo_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_all.drop('ve_number', axis=1,inplace=True)\n",
    "demo_all.set_index('ren_id', inplace=True)\n",
    "demo_all[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qe1 = \"select distinct on (ren_id) ren_id, lan_id_type, lan_power, lan_water, lan_gas, lan_drainage, \\\n",
    "    lds_code, lds_name, sub_name, lan_lds_nubmer, lan_multiple_zoning_flag, lan_lst_code, \\\n",
    "    sub_postcode, urt_urban_rural_ind from \" \n",
    "qe2 = \" t1 left join land_valuation_key t2 on (t1.ve_number = t2.ve_number) \\\n",
    "    left join land t3 on (t2.lan_id = t3.lan_id) \"\n",
    "\n",
    "fullqe = qe1+' train '+qe2+' union all '+qe1+' test '+qe2+';'\n",
    "\n",
    "%time land = pd.read_sql_query(fullqe, engine)\n",
    "land[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(land.index) != len(train.index) + len(test.index):\n",
    "    raise; # Something went wrong with the query\n",
    "else:\n",
    "    print len(land.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # make postcode categorical \n",
    "land['sub_postcode'] = ['P'+str(int(x)) if pd.notnull(x) else x for x in land.sub_postcode]\n",
    "land[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "land.sub_postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "land.set_index('ren_id', inplace=True)\n",
    "land[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print land.shape\n",
    "land.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we only have 8 null's so we will leave them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qc1 = \"select distinct on (ren_id) ren_id, t2.vec_cls_code, t2.cls_ve_use,  t3.cls_multi_res_ind from \"\n",
    "qc2 = \" t1 \\\n",
    "    left join valuation_entities_classifications t2 \\\n",
    "    on (t1.ve_number = t2.ve_number and t1.ren_date_eff_from > t2.vec_date_eff_from) \\\n",
    "    left join valuation_entities_classifications t3 \\\n",
    "    on (t2.ve_number = t3.ve_number and t3.vec_date_eff_from > t2.vec_date_eff_from) \"\n",
    "qc3 = \"group by t1.ren_id, t1.ve_number, t2.vec_cls_code, t2.cls_ve_use, t3.cls_multi_res_ind, t3.vec_date_eff_from ;\"\n",
    "\n",
    "fullqc = qc1+' train '+qc2+' union all '+qc1+' test '+qc2+qc3\n",
    "\n",
    "%time classf = pd.read_sql_query(fullqc, engine)\n",
    "classf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(classf.index) != len(train.index) + len(test.index):\n",
    "    raise;\n",
    "else:\n",
    "    print len(classf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classf.cls_ve_use.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # make categorical \n",
    "classf['vec_cls_code'] = ['C'+str(int(x)) if pd.notnull(x) else x for x in classf.vec_cls_code]\n",
    "classf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classf.cls_multi_res_ind.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classf.set_index('ren_id', inplace=True)\n",
    "classf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print classf.shape\n",
    "classf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute \n",
    "classf.loc[classf.cls_multi_res_ind.isnull(),'cls_multi_res_ind'] = 'N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# impute ren_lease_length\n",
    "def impute_rent(df, col):\n",
    "    df[col].replace('^12[a-zA-Z0-9_+ &]*','12m', regex=True, inplace=True)\n",
    "    df[col].replace('^6[a-zA-Z0-9_+ &]*','6m', regex=True, inplace=True)\n",
    "    df[col].replace('^52[a-zA-Z0-9_+ &]*','12m', regex=True, inplace=True)\n",
    "    df[col].replace('^1 year[a-zA-Z0-9_+ &]*','12m', regex=True, inplace=True)\n",
    "    df[col].replace('^1year[a-zA-Z0-9_+ &]*','12m', regex=True, inplace=True)\n",
    "    df[col].replace('^18[a-zA-Z0-9_+ &]*','18m', regex=True, inplace=True)\n",
    "    df[col].replace('^24[a-zA-Z0-9_+ &]*','24m', regex=True, inplace=True)\n",
    "    df[col].replace('^2yr[a-zA-Z0-9_+ &]*','24m', regex=True, inplace=True)\n",
    "    df[col].replace('^3yr[a-zA-Z0-9_+ &]*','36m', regex=True, inplace=True)\n",
    "    df[col].replace('','12m', regex=True, inplace=True)\n",
    "    df.loc[:,col] = df[col].fillna('12m')\n",
    "    # throw out the rest\n",
    "    bad_lease = df[col].value_counts()[7:].index\n",
    "    for s in bad_lease.values :\n",
    "        df[col].replace(s,'12m', inplace=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure there are no overlapping rents\n",
    "if (set(train.index) & set(test.index)) != set():\n",
    "    raise Exception(\"can't really append these df!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allset = train.append(test)\n",
    "if len(allset) != (len(train) + len(test)):\n",
    "    raise # Failure in append\n",
    "\n",
    "allset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(train.index) & set(allset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allset.ren_lease_length.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "impute_rent(allset,'ren_lease_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allset.ren_lease_length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a rent year\n",
    "allset.ren_date_eff_from = pd.to_datetime(allset.ren_date_eff_from)\n",
    "allset['rent_year'] = pd.PeriodIndex(allset.ren_date_eff_from, freq='A-DEC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the last rental rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qlast = \"select distinct on (ren_id) t1.ren_id, t1.ve_number, t1.ren_date_eff_from, \\\n",
    "    t2.ren_date_eff_from as ren_date_last, t2.ren_base_rent as last_rent from train t1 \\\n",
    "    left join train t2 on (t1.ve_number = t2.ve_number and t1.ren_date_eff_from > t2.ren_date_eff_from) \\\n",
    "    order by ren_id, t2.ren_date_eff_from desc;\"\n",
    "\n",
    "%time train_last_rent = pd.read_sql_query(qlast, engine)')\n",
    "print train_last_rent.shape\n",
    "train_last_rent[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_last_rent[train_last_rent.ve_number == 117993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from test\n",
    "qtlast = \"select distinct on (ren_id) t1.ren_id, t1.ve_number, t1.ren_date_eff_from, \\\n",
    "    t2.ren_date_eff_from, t2.ren_base_rent as ren_date_last from test t1 \\\n",
    "    left join train t2 on (t1.ve_number=t2.ve_number and t1.ren_date_eff_from > t2.ren_date_eff_from) \\\n",
    "    order by ren_id, t2.ren_date_eff_from desc ;\"\n",
    "\n",
    "%time test_last_rent = pd.read_sql_query(qtlast, engine)\n",
    "print last_rent.shape\n",
    "test_last_rent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_last_rent[test_last_rent.ve_number == 4192974]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_last_rent.to_csv('train12_last_rent.csv', index=False)\n",
    "test_last_rent.to_csv('test12_last_rent.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# so how many columns do we have?\n",
    "allcols =  len(allset.columns) + len(demo_all.columns) + len(quantity_features.columns) + len(quality_features.columns) + \\\n",
    "    len(dummy_quantity_final.columns) + len(dummy_quality_final.columns) + len(land.columns) + \\\n",
    "    len(classf.columns)\n",
    "allcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge into one big table\n",
    "allup = pd.concat([allset, demo_all, quantity_features, quality_features, dummy_quantity_final, dummy_quality_final, \n",
    "           land, classf], axis=1, join_axes=[allset.index])\n",
    "\n",
    "print allset.shape, allup.shape\n",
    "if (len(allset.index) != len(allup.index)) | (len(allup.columns) != allcols):\n",
    "    raise Exception('Not sure this merge is good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allup[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to re-impute all the new rows!\n",
    "\n",
    "allup.loc[:,quantity_features.columns] = allup.loc[:,quantity_features.columns].fillna(0)\n",
    "allup.loc[:,quality_features.columns] = allup.loc[:,quality_features.columns].fillna('0')\n",
    "allup.loc[:,dummy_quantity_final.columns] = allup.loc[:,dummy_quantity_final.columns].fillna(0)\n",
    "allup.loc[:,dummy_quality_final.columns] = allup.loc[:,dummy_quality_final.columns].fillna('0')\n",
    "allup.loc[allup.cls_multi_res_ind.isnull(),'cls_multi_res_ind'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allup.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split train and test again\n",
    "train_big = allup.loc[train.index]\n",
    "test_big = allup.loc[test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(train.index) & set(allup.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_big.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_big[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_big.ren_date_eff_from.groupby(train_big.ren_date_eff_from.dt.year).count().plot(kind='bar', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.ren_date_eff_from.groupby(test.ren_date_eff_from.dt.year).count().plot(kind='bar', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do we have data on any property rented more than once ?  No.\n",
    "# double checking above: all ren_id's are unique\n",
    "len(train.index) == len(train.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_big.lan_id.unique()) / len(train_big.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test_big.lan_id.unique()) / len(test_big.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# is the financial status in line?\n",
    "fin_status = pd.DataFrame([train_big.financial_status.value_counts(), test_big.financial_status.value_counts()])\n",
    "fin_status.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many places don't overlap?\n",
    "print 'train: ', len(set(train_big.lnp_pin.unique()) - set(test_big.lnp_pin.unique()))\n",
    "print 'test: ', len(set(test_big.lnp_pin.unique()) - set(train_big.lnp_pin.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do the ve_numbers overlap?\n",
    "len(set(train_big.ve_number.unique()) & set(test_big.ve_number.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# throw out unecessary columns / features\n",
    "allsub = allup.copy()\n",
    "allsub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(set(train.index) & set(allsub.index)) != len(train.index):\n",
    "    raise Exception('bad stuff happened to the allsub index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allup[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# thow out all rents older than 2001\n",
    "allsub = allsub[(allsub.ren_date_eff_from > pd.datetime(2000,12,31))]\n",
    "allsub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_trim = train[(train.ren_date_eff_from > pd.datetime(2000,12,31))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(set(train_trim.index) & set(allsub.index)) != len(train_trim.index):\n",
    "    raise Exception('bad stuff happened to the allsub index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.ren_base_rent.plot(use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.sort_values(by='ren_base_rent', ascending=False).ren_base_rent[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop bad rents\n",
    "maxrent = 5000\n",
    "print allsub.shape\n",
    "bad_rents = allsub[allsub.ren_base_rent > maxrent].index\n",
    "print len(bad_rents)\n",
    "allsub.drop(bad_rents, inplace=True)\n",
    "train_trim = train_trim[train_trim.ren_base_rent < maxrent]\n",
    "print allsub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(set(train_trim.index) & set(allsub.index)) != len(train_trim.index):\n",
    "    raise Exception('bad stuff happened to the allsub index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shift rents over 7 years - no, don't\n",
    "# m = (29.656 / (10*12)) \n",
    "# b = 110\n",
    "# from_date = pd.datetime(2001,1,1)\n",
    "# to_date = pd.datetime(2008,1,1)\n",
    "# the_delta = to_date - from_date\n",
    "# years = int(the_delta.days / 365)\n",
    "# changeidx = train2_overlap[train2_overlap.ren_date_eff_from < to_date].index\n",
    "# orig_dates = train2_overlap.ren_date_eff_from.copy()  # keep a copy, just in case\n",
    "# train2_overlap.ix[changeidx].ren_base_rent = (train2_overlap.ix[changeidx].ren_base_rent * years * m) + b\n",
    "# train2_overlap.ix[changeidx,'ren_date_eff_from'] = train2_overlap.ix[changeidx].ren_date_eff_from + the_delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the dates moved\n",
    "# [y for y, g in train2_overlap.ix[changeidx].ren_date_eff_from.groupby(train2_overlap.ix[changeidx].ren_date_eff_from.dt.year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and look at the rent distribution\n",
    "allsub.ren_date_eff_from.groupby(allsub.ren_date_eff_from.dt.year).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at kitchen values\n",
    "allsub.kitchen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix all the rows with more than 4 kitchens ! \n",
    "allsub.loc[allsub.kitchen > 5,'kitchen'] = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.lounge_room.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix all the rows with more than 4 lounge rooms ! \n",
    "allsub.loc[allsub.lounge_room > 5,'lounge_room'] = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_counts = []\n",
    "for c in allsub.columns.values:\n",
    "    col_counts.append([c, allsub[c].notnull().sum()])\n",
    "\n",
    "col_counts = pd.DataFrame(col_counts, columns=['feature', 'howmany'])\n",
    "col_counts.sort_values(by='howmany', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quantity_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.sort_values(by='house_area').house_area.plot(use_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.sort_values(by='house_area', ascending=False).house_area[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.loc[train.index][allsub.loc[train.index].house_area > 5000].house_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.loc[640530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some of these house areas are in the test set, so I think they are fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate rent estimates\n",
    "Find the mean of area rents per year, and the rent that is a comprable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(set(train_trim.index) & set(allsub.index)) != len(train_trim.index):\n",
    "    raise Exception('bad stuff happened to the allsub index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load mean_rents\n",
    "mean_rents = pd.read_csv('mean_rents_per_year.csv')\n",
    "mean_rents.rent_year = pd.PeriodIndex(mean_rents.rent_year, freq='A-DEC')\n",
    "mean_rents = mean_rents[mean_rents.rent_year > pd.Period(2008, freq='A-DEC') ]\n",
    "mean_rents.set_index('rent_year', inplace=True)\n",
    "mean_rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Generate the mean_rent per sa4_code_2011 table if we could not load it previously\n",
    "\n",
    "# zips = allsub.sa4_code_2011.unique()\n",
    "# zips.sort()\n",
    "# years = pd.period_range('2000', '2015', freq='A')\n",
    "# rent_sa4 = pd.DataFrame(columns=zips, index=years)\n",
    "# rent_sa4.index.name = 'date'\n",
    "# rent_years = allsub[['ren_base_rent', 'rent_year', 'sa4_code_2011']]\n",
    "# mean_rents = rent_years.groupby(['rent_year', 'sa4_code_2011'])['ren_base_rent'].mean()\n",
    "# mean_rents = mean_rents.unstack() #['year', 'sa4_code_2011'])\n",
    "# mean_rents = mean_rents.fillna(axis='index', method='bfill')\n",
    "# mean_rents = mean_rents.fillna(axis='index', method='ffill')\n",
    "# mean_rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # if we have stripped all categorical strings, then we need to strip the zip_code strings\n",
    "mean_rents.columns = [int(x[1:]) for x  in mean_rents.columns ]\n",
    "mean_rents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this took a while\n",
    "print 'starting:', pd.datetime.now()\n",
    "for a in mean_rents.columns: # for every zip\n",
    "    for y in mean_rents.index: # for every year\n",
    "        allsub.loc[((allsub.rent_year == y) & (allsub.sa4_code_2011 == a)), 'sa4_mean_rent'] = mean_rents.loc[y,a]\n",
    "    print a, pd.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_rents.to_csv('mean_rents_per_year_12.csv')\n",
    "allsub.sa4_mean_rent.to_csv('sa4_mean_rent_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub[allsub.sa4_mean_rent.notnull()].sa4_mean_rent[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allsub['log_sa4_mean_rent'] = log(allsub.sa4_mean_rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allsub['sa4_mean_rent_rooms'] = allsub.sa4_mean_rent / allsub.effective_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DONE !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one last look at all features and value ranges\n",
    "\n",
    "df = allsub\n",
    "print df.shape\n",
    "for c in df.columns:\n",
    "    valcnt = len(df[c].unique())\n",
    "    vals = df[c].unique()[:10]\n",
    "    print c, valcnt, vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub.storey.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub[allsub.storey > 3][['ve_number','storey']].sort_values(by='storey', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arbirtrarily cut off the high end\n",
    "# TODO: move this up to quantity_features\n",
    "quantity_features.loc[quantity_features.storey > 11,'storey'] = 10\n",
    "allsub.loc[allsub.storey > 11,'storey'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub[allsub.toilet > 4][['ve_number','toilet']].sort_values(by='toilet', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arbirtrarily cut off the high end\n",
    "# TODO: a better way is to cap this at max(bath_room)\n",
    "# move this up to quantity_features\n",
    "quantity_features.loc[quantity_features.toilet > 9,'toilet'] = 9\n",
    "allsub.loc[allsub.toilet > 9,'toilet'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub[allsub.bath_room > 4][['ve_number','bath_room']].sort_values(by='bath_room', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allsub[allsub.ensuite > 4][['ve_number','ensuite']].sort_values(by='ensuite', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the ramaining bad rooms from the train set\n",
    "remaining_bad_rooms = list(set(bad_train_rooms.index).intersection(allsub.index))\n",
    "allsub.drop(remaining_bad_rooms, inplace=True)\n",
    "print len(remaining_bad_rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensuite should be capped at max(bedrooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear up some space, we are going to need it\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and test again\n",
    "train_final = allsub.loc[train_trim.index].copy()\n",
    "test_final = allsub.loc[test.index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print train_final.shape\n",
    "train_final.to_csv('train12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # throw out anything older than 2004\n",
    "# print train_final.shape\n",
    "# train_final = train_final[train_final.ren_date_eff_from > pd.datetime(2003,12,31)]\n",
    "# print train_final.shape\n",
    "# train_final.to_csv('train12_2004.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # reduce the data set to overlapping lnp_pin's \n",
    "# overlap_lnp_pin = set(train_final.lnp_pin.unique()) & set(test_final.lnp_pin.unique())\n",
    "# train_final = train_final[train_final.lnp_pin.isin(overlap_lnp_pin)]\n",
    "# print train_final.shape\n",
    "# train_final.to_csv('rent_train12_2004_lnp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print allsub.shape\n",
    "print train_final.shape\n",
    "print test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allsub.to_csv('allsub12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_final.to_csv('test12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_time = pd.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
